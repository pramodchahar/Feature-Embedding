{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "A word embedding is an approach to provide a dense vector representation of words that capture something about their meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embeddings are an improvement over simpler bag-of-word model word encoding schemes like word counts and frequencies that result in large and sparse vectors (mostly 0 values) that describe documents but not the meaning of the words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embeddings work by using an algorithm to train a set of fixed-length dense and continuous-valued vectors based on a large corpus of text. Each word is represented by a point in the embedding space and these points are learned and moved around based on the words that surround the target word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim is an open source Python library for natural language processing, with a focus on topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading https://files.pythonhosted.org/packages/33/33/df6cb7acdcec5677ed130f4800f67509d24dbec74a03c329fcbf6b0864f0/gensim-3.4.0-cp36-cp36m-manylinux1_x86_64.whl (22.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 22.6MB 36kB/s eta 0:00:011  5% |█▋                              | 1.1MB 5.4MB/s eta 0:00:04    31% |██████████                      | 7.0MB 5.4MB/s eta 0:00:03    33% |██████████▋                     | 7.5MB 8.7MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.6/site-packages (from gensim)\n",
      "Collecting smart-open>=1.2.1 (from gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/4b/69/c92661a333f733510628f28b8282698b62cdead37291c8491f3271677c02/smart_open-1.5.7.tar.gz\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.6/site-packages (from gensim)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.6/site-packages (from gensim)\n",
      "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/bd/b7/a88a67002b1185ed9a8e8a6ef15266728c2361fcb4f1d02ea331e4c7741d/boto-2.48.0-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 513kB/s ta 0:00:011\n",
      "\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from smart-open>=1.2.1->gensim)\n",
      "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/90/88/acf7e4ec3a31c0d3da51037c6c94cc93a7595d4eb04fbb01e7f4f4e2dbc5/boto3-1.7.31-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 2.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Collecting botocore<1.11.0,>=1.10.31 (from boto3->smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/11/5c/a64d7550362200100e145519952a651e43342c848c9988f37c3403caab7a/botocore-1.10.31-py2.py3-none-any.whl (4.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 4.3MB 178kB/s ta 0:00:011   33% |██████████▉                     | 1.5MB 2.0MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
      "Collecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 1.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /opt/conda/lib/python3.6/site-packages (from botocore<1.11.0,>=1.10.31->boto3->smart-open>=1.2.1->gensim)\n",
      "Collecting docutils>=0.10 (from botocore<1.11.0,>=1.10.31->boto3->smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
      "\u001b[K    100% |████████████████████████████████| 552kB 856kB/s ta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: smart-open, bz2file\n",
      "  Running setup.py bdist_wheel for smart-open ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/b1/9e/7d/bb3d3b55c597e72617140a0638c06382a5f17283881eae163e\n",
      "  Running setup.py bdist_wheel for bz2file ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
      "Successfully built smart-open bz2file\n",
      "Installing collected packages: boto, bz2file, jmespath, docutils, botocore, s3transfer, boto3, smart-open, gensim\n",
      "Successfully installed boto-2.48.0 boto3-1.7.31 botocore-1.10.31 bz2file-0.98 docutils-0.14 gensim-3.4.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.5.7\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* size: (default 100) The number of dimensions of the embedding, e.g. the length of the dense vector to represent each token (word).\n",
    "* window: (default 5) The maximum distance between a target word and words around the target word.\n",
    "* min_count: (default 5) The minimum count of words to consider when training the model; words with an occurrence less than this count will be ignored.\n",
    "* workers: (default 3) The number of threads to use while training.\n",
    "* sg: (default 0 or CBOW) The training algorithm, either CBOW (0) or skip gram (1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df=pd.read_csv('reviews.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is a great movie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I liked the length of the movie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I did not like the movie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             review  label\n",
       "0             this is a great movie      1\n",
       "1  I liked the length of the movie       1\n",
       "2          I did not like the movie      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenzied']=df[\"review\"].str.split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, Word2Vec expects to be given a list of sentences, each of which is a list of words. To make this data setup, we define a function to split our sentences into lists of words and then apply this within another function that splits our texts into lists of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(df['tokenzied'], min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=27, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize vocabulary\n",
    "words = list(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'great',\n",
       " 'movie',\n",
       " 'i',\n",
       " 'liked',\n",
       " 'the',\n",
       " 'length',\n",
       " 'of',\n",
       " '',\n",
       " 'did',\n",
       " 'not',\n",
       " 'like',\n",
       " 'should',\n",
       " 'have',\n",
       " 'gone',\n",
       " 'to',\n",
       " 'will',\n",
       " 'try',\n",
       " 'another',\n",
       " 'please',\n",
       " 'donõt',\n",
       " 'watch',\n",
       " 'best',\n",
       " 'use',\n",
       " 'time']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.09633644e-04   3.70263751e-03   2.38276972e-03  -3.87261924e-03\n",
      "   3.09008430e-03  -3.69046163e-03  -5.54425584e-04  -2.06267717e-03\n",
      "  -3.19953506e-05   4.66789724e-03   3.14125558e-03   2.37497129e-03\n",
      "  -2.04226188e-03   3.44053190e-03  -6.20116480e-04   7.44130870e-04\n",
      "   1.18909136e-03  -2.66512646e-03  -1.15553506e-04   5.24986594e-04\n",
      "  -2.51844712e-03  -1.74200255e-03   2.53457529e-03   4.45861602e-03\n",
      "  -8.28336400e-04  -3.58780287e-03  -4.10189899e-03   1.75538671e-03\n",
      "  -4.87980293e-03  -1.64285919e-03   3.67766595e-03  -2.67773808e-04\n",
      "   6.63481886e-04   3.90672730e-03  -2.53078528e-03   2.92938971e-03\n",
      "   4.41400008e-03   4.71163075e-03  -2.33827275e-03   3.92537657e-03\n",
      "   2.13778228e-03  -2.83788703e-03   9.19706144e-05  -1.64399657e-03\n",
      "   1.05461280e-03  -2.20665173e-03  -1.96755980e-03  -4.37681517e-03\n",
      "  -3.96122830e-03   2.14403844e-03  -3.84839205e-03   4.28637536e-03\n",
      "   4.63919714e-03   4.99490241e-04   7.11607339e-04  -4.36716713e-03\n",
      "   1.49905623e-03  -3.77917616e-03   3.05006106e-04   1.27072411e-03\n",
      "  -1.16014015e-03  -3.66069679e-03  -4.71596885e-03  -4.85759880e-03\n",
      "   8.89829884e-04  -4.98925801e-03   1.10389956e-03   4.14448231e-03\n",
      "   3.84511822e-03   1.71479757e-03   2.43727909e-03   4.32930561e-03\n",
      "   3.97739792e-03   2.09447564e-04  -2.75104842e-03  -1.72952248e-03\n",
      "   1.98154082e-03   4.66755591e-03  -4.31907736e-03  -3.91377462e-03\n",
      "  -1.62075949e-03  -3.28996871e-03  -2.80985190e-03   1.72394945e-03\n",
      "   3.75871616e-03   3.97741236e-03   3.48669547e-03   2.61070277e-03\n",
      "   2.17775349e-03   3.20713560e-04   2.72479025e-03  -3.78098944e-03\n",
      "  -2.64115771e-03   2.50302954e-03  -4.26731957e-03   1.89563003e-03\n",
      "  -2.72767060e-03  -4.17337473e-03  -3.85268009e-03  -4.03281394e-03]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# access vector for one word\n",
    "print(model['watch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenzied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is a great movie</td>\n",
       "      <td>1</td>\n",
       "      <td>[this, is, a, great, movie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i liked the length of the movie</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, liked, the, length, of, the, movie, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i did not like the movie</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, did, not, like, the, movie]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             review  label  \\\n",
       "0             this is a great movie      1   \n",
       "1  i liked the length of the movie       1   \n",
       "2          i did not like the movie      0   \n",
       "\n",
       "                                   tokenzied  \n",
       "0                [this, is, a, great, movie]  \n",
       "1  [i, liked, the, length, of, the, movie, ]  \n",
       "2            [i, did, not, like, the, movie]  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(text):\n",
    "    return np.array([model[x] for x in text])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# apply the preprocess function to all reviews\n",
    "df['vec_text'] = df['tokenzied'].apply(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sent_vec']=list(map(lambda x:x.sum(axis=0),df.vec_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(df['sent_vec'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 100)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.001679</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>-0.012190</td>\n",
       "      <td>0.013261</td>\n",
       "      <td>-0.001130</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>-0.000820</td>\n",
       "      <td>-0.003699</td>\n",
       "      <td>0.002799</td>\n",
       "      <td>-0.000391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>-0.000990</td>\n",
       "      <td>-0.005109</td>\n",
       "      <td>0.010388</td>\n",
       "      <td>0.010266</td>\n",
       "      <td>-0.015650</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>0.005719</td>\n",
       "      <td>0.012310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.008320</td>\n",
       "      <td>-0.003231</td>\n",
       "      <td>-0.010294</td>\n",
       "      <td>-0.005250</td>\n",
       "      <td>-0.011670</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>-0.000537</td>\n",
       "      <td>0.015894</td>\n",
       "      <td>-0.005816</td>\n",
       "      <td>-0.013788</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003410</td>\n",
       "      <td>-0.000831</td>\n",
       "      <td>0.007358</td>\n",
       "      <td>-0.003313</td>\n",
       "      <td>0.019346</td>\n",
       "      <td>0.006974</td>\n",
       "      <td>-0.011077</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.007877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.006566</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>-0.001793</td>\n",
       "      <td>-0.000389</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>0.006649</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>-0.000466</td>\n",
       "      <td>-0.001075</td>\n",
       "      <td>-0.001082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.006896</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>-0.007766</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.011406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.005039</td>\n",
       "      <td>0.014803</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>0.003938</td>\n",
       "      <td>0.008560</td>\n",
       "      <td>-0.004391</td>\n",
       "      <td>0.003821</td>\n",
       "      <td>-0.012251</td>\n",
       "      <td>-0.011578</td>\n",
       "      <td>0.006688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001032</td>\n",
       "      <td>-0.014480</td>\n",
       "      <td>0.015763</td>\n",
       "      <td>-0.006751</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.011469</td>\n",
       "      <td>-0.007362</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>0.015280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010930</td>\n",
       "      <td>-0.006461</td>\n",
       "      <td>-0.001861</td>\n",
       "      <td>0.003614</td>\n",
       "      <td>-0.002374</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.008267</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>-0.004337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003912</td>\n",
       "      <td>-0.003774</td>\n",
       "      <td>-0.003448</td>\n",
       "      <td>-0.004118</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>-0.006517</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>-0.003789</td>\n",
       "      <td>0.011328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004003</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>-0.005221</td>\n",
       "      <td>0.007832</td>\n",
       "      <td>0.011042</td>\n",
       "      <td>-0.011512</td>\n",
       "      <td>0.005874</td>\n",
       "      <td>-0.008491</td>\n",
       "      <td>-0.006839</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005712</td>\n",
       "      <td>-0.010749</td>\n",
       "      <td>-0.006398</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000387</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>-0.012781</td>\n",
       "      <td>-0.005410</td>\n",
       "      <td>-0.002541</td>\n",
       "      <td>0.007355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>-0.004637</td>\n",
       "      <td>0.003078</td>\n",
       "      <td>-0.005869</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.005624</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>0.006560</td>\n",
       "      <td>-0.003168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>-0.009482</td>\n",
       "      <td>0.005547</td>\n",
       "      <td>-0.004015</td>\n",
       "      <td>-0.006422</td>\n",
       "      <td>-0.006949</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.004426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.001679  0.002369 -0.012190  0.013261 -0.001130  0.004322 -0.000820   \n",
       "1 -0.008320 -0.003231 -0.010294 -0.005250 -0.011670  0.002519 -0.000537   \n",
       "2 -0.006566  0.004054 -0.001793 -0.000389 -0.000106  0.006649 -0.000122   \n",
       "3 -0.005039  0.014803  0.004784  0.003938  0.008560 -0.004391  0.003821   \n",
       "4  0.010930 -0.006461 -0.001861  0.003614 -0.002374  0.003197  0.001534   \n",
       "5  0.004003  0.005289 -0.005221  0.007832  0.011042 -0.011512  0.005874   \n",
       "6  0.001420  0.002101 -0.004637  0.003078 -0.005869  0.000756  0.005624   \n",
       "\n",
       "         7         8         9     ...           90        91        92  \\\n",
       "0 -0.003699  0.002799 -0.000391    ...     0.000428  0.000418 -0.000990   \n",
       "1  0.015894 -0.005816 -0.013788    ...    -0.003410 -0.000831  0.007358   \n",
       "2 -0.000466 -0.001075 -0.001082    ...     0.011800  0.001475  0.006896   \n",
       "3 -0.012251 -0.011578  0.006688    ...    -0.001032 -0.014480  0.015763   \n",
       "4  0.008267  0.007800 -0.004337    ...     0.003912 -0.003774 -0.003448   \n",
       "5 -0.008491 -0.006839  0.005848    ...    -0.005712 -0.010749 -0.006398   \n",
       "6  0.007980  0.006560 -0.003168    ...     0.002237  0.009013  0.001045   \n",
       "\n",
       "         93        94        95        96        97        98        99  \n",
       "0 -0.005109  0.010388  0.010266 -0.015650  0.003815  0.005719  0.012310  \n",
       "1 -0.003313  0.019346  0.006974 -0.011077  0.010740  0.009000  0.007877  \n",
       "2  0.000904 -0.000249  0.003613 -0.007766  0.003834  0.009996  0.011406  \n",
       "3 -0.006751  0.005362  0.011469 -0.007362  0.003082  0.004728  0.015280  \n",
       "4 -0.004118  0.007381  0.006081 -0.006517  0.001990 -0.003789  0.011328  \n",
       "5 -0.000234 -0.000387  0.006732 -0.012781 -0.005410 -0.002541  0.007355  \n",
       "6 -0.009482  0.005547 -0.004015 -0.006422 -0.006949  0.001613  0.004426  \n",
       "\n",
       "[7 rows x 100 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=df.merge(X, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenzied</th>\n",
       "      <th>vec_text</th>\n",
       "      <th>sent_vec</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is a great movie</td>\n",
       "      <td>1</td>\n",
       "      <td>[this, is, a, great, movie]</td>\n",
       "      <td>[[-0.00286979, 0.00450099, -0.00367972, 0.0025...</td>\n",
       "      <td>[-0.00167917, 0.00236917, -0.0121904, 0.013261...</td>\n",
       "      <td>-0.001679</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>-0.012190</td>\n",
       "      <td>0.013261</td>\n",
       "      <td>-0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>-0.000990</td>\n",
       "      <td>-0.005109</td>\n",
       "      <td>0.010388</td>\n",
       "      <td>0.010266</td>\n",
       "      <td>-0.015650</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>0.005719</td>\n",
       "      <td>0.012310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i liked the length of the movie</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, liked, the, length, of, the, movie, ]</td>\n",
       "      <td>[[-0.00258756, -0.000346607, -0.000324643, -0....</td>\n",
       "      <td>[-0.00831955, -0.00323095, -0.010294, -0.00524...</td>\n",
       "      <td>-0.008320</td>\n",
       "      <td>-0.003231</td>\n",
       "      <td>-0.010294</td>\n",
       "      <td>-0.005250</td>\n",
       "      <td>-0.011670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003410</td>\n",
       "      <td>-0.000831</td>\n",
       "      <td>0.007358</td>\n",
       "      <td>-0.003313</td>\n",
       "      <td>0.019346</td>\n",
       "      <td>0.006974</td>\n",
       "      <td>-0.011077</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.007877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i did not like the movie</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, did, not, like, the, movie]</td>\n",
       "      <td>[[-0.00258756, -0.000346607, -0.000324643, -0....</td>\n",
       "      <td>[-0.00656643, 0.00405386, -0.00179299, -0.0003...</td>\n",
       "      <td>-0.006566</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>-0.001793</td>\n",
       "      <td>-0.000389</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.006896</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>-0.007766</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.011406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             review  label  \\\n",
       "0             this is a great movie      1   \n",
       "1  i liked the length of the movie       1   \n",
       "2          i did not like the movie      0   \n",
       "\n",
       "                                   tokenzied  \\\n",
       "0                [this, is, a, great, movie]   \n",
       "1  [i, liked, the, length, of, the, movie, ]   \n",
       "2            [i, did, not, like, the, movie]   \n",
       "\n",
       "                                            vec_text  \\\n",
       "0  [[-0.00286979, 0.00450099, -0.00367972, 0.0025...   \n",
       "1  [[-0.00258756, -0.000346607, -0.000324643, -0....   \n",
       "2  [[-0.00258756, -0.000346607, -0.000324643, -0....   \n",
       "\n",
       "                                            sent_vec         0         1  \\\n",
       "0  [-0.00167917, 0.00236917, -0.0121904, 0.013261... -0.001679  0.002369   \n",
       "1  [-0.00831955, -0.00323095, -0.010294, -0.00524... -0.008320 -0.003231   \n",
       "2  [-0.00656643, 0.00405386, -0.00179299, -0.0003... -0.006566  0.004054   \n",
       "\n",
       "          2         3         4    ...           90        91        92  \\\n",
       "0 -0.012190  0.013261 -0.001130    ...     0.000428  0.000418 -0.000990   \n",
       "1 -0.010294 -0.005250 -0.011670    ...    -0.003410 -0.000831  0.007358   \n",
       "2 -0.001793 -0.000389 -0.000106    ...     0.011800  0.001475  0.006896   \n",
       "\n",
       "         93        94        95        96        97        98        99  \n",
       "0 -0.005109  0.010388  0.010266 -0.015650  0.003815  0.005719  0.012310  \n",
       "1 -0.003313  0.019346  0.006974 -0.011077  0.010740  0.009000  0.007877  \n",
       "2  0.000904 -0.000249  0.003613 -0.007766  0.003834  0.009996  0.011406  \n",
       "\n",
       "[3 rows x 105 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=final_df.iloc[:,final_df.columns !='review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=final_df.iloc[:,final_df.columns !='tokenzied']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=final_df.iloc[:,final_df.columns !='vec_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=final_df.iloc[:,final_df.columns !='sent_vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 101)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.001679</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>-0.012190</td>\n",
       "      <td>0.013261</td>\n",
       "      <td>-0.001130</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>-0.000820</td>\n",
       "      <td>-0.003699</td>\n",
       "      <td>0.002799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>-0.000990</td>\n",
       "      <td>-0.005109</td>\n",
       "      <td>0.010388</td>\n",
       "      <td>0.010266</td>\n",
       "      <td>-0.015650</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>0.005719</td>\n",
       "      <td>0.012310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.008320</td>\n",
       "      <td>-0.003231</td>\n",
       "      <td>-0.010294</td>\n",
       "      <td>-0.005250</td>\n",
       "      <td>-0.011670</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>-0.000537</td>\n",
       "      <td>0.015894</td>\n",
       "      <td>-0.005816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003410</td>\n",
       "      <td>-0.000831</td>\n",
       "      <td>0.007358</td>\n",
       "      <td>-0.003313</td>\n",
       "      <td>0.019346</td>\n",
       "      <td>0.006974</td>\n",
       "      <td>-0.011077</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.007877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.006566</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>-0.001793</td>\n",
       "      <td>-0.000389</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>0.006649</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>-0.000466</td>\n",
       "      <td>-0.001075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.006896</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>-0.007766</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.011406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label         0         1         2         3         4         5  \\\n",
       "0      1 -0.001679  0.002369 -0.012190  0.013261 -0.001130  0.004322   \n",
       "1      1 -0.008320 -0.003231 -0.010294 -0.005250 -0.011670  0.002519   \n",
       "2      0 -0.006566  0.004054 -0.001793 -0.000389 -0.000106  0.006649   \n",
       "\n",
       "          6         7         8    ...           90        91        92  \\\n",
       "0 -0.000820 -0.003699  0.002799    ...     0.000428  0.000418 -0.000990   \n",
       "1 -0.000537  0.015894 -0.005816    ...    -0.003410 -0.000831  0.007358   \n",
       "2 -0.000122 -0.000466 -0.001075    ...     0.011800  0.001475  0.006896   \n",
       "\n",
       "         93        94        95        96        97        98        99  \n",
       "0 -0.005109  0.010388  0.010266 -0.015650  0.003815  0.005719  0.012310  \n",
       "1 -0.003313  0.019346  0.006974 -0.011077  0.010740  0.009000  0.007877  \n",
       "2  0.000904 -0.000249  0.003613 -0.007766  0.003834  0.009996  0.011406  \n",
       "\n",
       "[3 rows x 101 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
